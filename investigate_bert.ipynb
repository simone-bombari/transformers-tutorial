{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abfe45c7-51d2-4fd1-87f3-11a454966ff8",
   "metadata": {},
   "source": [
    "# Bert playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97840c52-9de8-483b-a05f-8caac6d70031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "config = BertConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "model = BertModel.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27c038-584c-486e-b964-1d4088e16a53",
   "metadata": {},
   "source": [
    "### Tokenize and encode two different sentences containing the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484770a-d90f-4f7a-bf63-b3188cf16d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"I love her much\"\n",
    "text2 = \"Much love for her\"\n",
    "inputs1 = tokenizer(text1, return_tensors=\"pt\", padding=False, truncation=True)\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\", padding=False, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8c47f-3b64-402d-8da8-0b3764598c04",
   "metadata": {},
   "source": [
    "### Extract word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f8ffd-07f0-4698-b807-dbbf8bf51519",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs1 = model.embeddings.word_embeddings(inputs1[\"input_ids\"])\n",
    "    outputs2 = model.embeddings.word_embeddings(inputs2[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0c2d9-be22-448c-af96-0985a68eaf52",
   "metadata": {},
   "source": [
    "### Find index of the word 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6399b03-83d0-42ee-a712-2488fceb1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "love_index = tokenizer.convert_tokens_to_ids('love')\n",
    "love_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e102b5-8d0b-45a6-85c1-9a3d97b26542",
   "metadata": {},
   "source": [
    "### Assuming 'love' is present in both sentences, compare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081feb4-d2c2-45e0-ba06-c6dbc268eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = outputs1[:, inputs1[\"input_ids\"][0] == love_index, :]\n",
    "embedding2 = outputs2[:, inputs2[\"input_ids\"][0] == love_index, :]\n",
    "\n",
    "print(torch.allclose(embedding1, embedding2, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5d79e-a87d-414f-a2bb-119de8750147",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517be3d-7d69-4998-9adf-e1281f6a12ac",
   "metadata": {},
   "source": [
    "# Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279bf1a-7164-445e-b19b-ae9d61c6f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "love_index = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d5db7-69c0-4a8f-b3f4-9b2ceb17b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embeddings = model.embeddings.position_embeddings.weight\n",
    "pos_embedding = positional_embeddings[love_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894267d-b19c-4a28-9890-d5a31b325672",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b7a07-02c7-4d44-8b41-2a05772f8104",
   "metadata": {},
   "source": [
    "# Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfef09-e500-4696-a5fc-5e1617f80da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love her much\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "word_embeddings = model.embeddings.word_embeddings(input_ids)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = model.embeddings(input_ids=input_ids)\n",
    "    assert (embeddings == outputs[2][0]).all()\n",
    "\n",
    "manual_sum = word_embeddings[0, love_index] + positional_embeddings[love_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849af1a-ba49-48ef-9297-d446044ddeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.allclose(embeddings[0][love_index], manual_sum, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d563cca-96dd-4833-a7f9-0fd08fb928b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80cf3a-3985-4e68-99ba-11ce69ae5c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a77a81-0136-40b9-8749-40178e2f6e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868821f-4365-4d03-850a-386d09c66196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57038f96-adac-43ac-bc37-4d583e7f365c",
   "metadata": {},
   "source": [
    "## Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76b0dd7-d2cc-4b69-828f-14e2b9d6faa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a8006-24ab-480c-a9f9-2ed6a678104d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e64715-d7c3-4aee-b8ff-1984b888fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20758ba6-c096-4298-ac97-8551e1e58853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d9373-e5b9-4d22-ab51-be77a3b2f1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef447d-9597-4210-8bfd-483635dbfbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9329723-6120-4d77-9a2d-6d785004f184",
   "metadata": {},
   "source": [
    "### In Bert, we need to add token type and LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edd595-f868-44b0-9d29-d2e4e16cec61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manual_sum_with_type = manual_sum + model.embeddings.token_type_embeddings.weight[0]\n",
    "manual_sum_with_layer_norm = model.embeddings.LayerNorm(manual_sum_with_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de1635-704f-48ce-9d79-dab72e497732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.allclose(embeddings[0][love_index], manual_sum_with_layer_norm, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847798d0-18c5-47bf-98ce-bfa80dc2393e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbaec9-e6f1-4e4b-aaac-6d0f413c09b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995df36-6264-4ae5-b418-3b105087e8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb267f50-7750-4186-b1cd-1fa3c84f5a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91a1e5b9-032a-4e6d-b7f3-16513493eaba",
   "metadata": {},
   "source": [
    "### How does LayerNorm work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204d928a-fb49-4c8d-a372-39f572ff4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = model.embeddings.LayerNorm.weight\n",
    "beta = model.embeddings.LayerNorm.bias\n",
    "epsilon = 1e-12\n",
    "\n",
    "mean = manual_sum_with_type.mean(dim=-1, keepdim=True)\n",
    "variance = manual_sum_with_type.var(dim=-1, keepdim=True, unbiased=False)\n",
    "\n",
    "normalized = (manual_sum_with_type - mean) / torch.sqrt(variance + epsilon)\n",
    "\n",
    "layer_normed_embeddings = gamma * normalized + beta\n",
    "print(torch.allclose(model.embeddings.LayerNorm(manual_sum_with_type), layer_normed_embeddings, atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2703f74-9fdf-44ce-8706-1b9cd53325cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7b9fa82-4d72-4d42-b6c4-f67530c1099f",
   "metadata": {},
   "source": [
    "# Now, let's compute the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8ca92-4ce7-4baa-8466-35b510194541",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 12\n",
    "head = 0\n",
    "\n",
    "head_size = model.config.hidden_size // num_heads\n",
    "rows_start = head * head_size\n",
    "rows_end = (head + 1) * head_size\n",
    "\n",
    "q_weight = model.encoder.layer[0].attention.self.query.weight\n",
    "k_weight = model.encoder.layer[0].attention.self.key.weight\n",
    "v_weight = model.encoder.layer[0].attention.self.value.weight\n",
    "\n",
    "q_bias = model.encoder.layer[0].attention.self.query.bias\n",
    "k_bias = model.encoder.layer[0].attention.self.key.bias\n",
    "v_bias = model.encoder.layer[0].attention.self.value.bias\n",
    "\n",
    "q_weight_head = q_weight[rows_start:rows_end]\n",
    "k_weight_head = k_weight[rows_start:rows_end]\n",
    "v_weight_head = v_weight[rows_start:rows_end]\n",
    "\n",
    "q_bias_head = q_bias[rows_start:rows_end]\n",
    "k_bias_head = k_bias[rows_start:rows_end]\n",
    "v_bias_head = v_bias[rows_start:rows_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8418e-6e7e-4ac8-8fd7-e134649cb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_head = torch.matmul(embeddings, q_weight_head.T) + q_bias_head\n",
    "keys_head = torch.matmul(embeddings, k_weight_head.T) + k_bias_head\n",
    "values_head = torch.matmul(embeddings, v_weight_head.T) + v_bias_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837006f-190a-4dc4-8396-1248184ac9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores_head = torch.matmul(queries_head, keys_head.transpose(-2, -1))\n",
    "attention_scores_head /= torch.sqrt(torch.tensor(head_size, dtype=torch.float32))\n",
    "attention_probs_head = torch.softmax(attention_scores_head, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bde395-9c68-44b6-8ef1-c0879f1f6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs['input_ids'], output_attentions=True)\n",
    "direct_attention_scores = outputs.attentions[0]  # For the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eaba6f-967a-4347-853d-1b6658a166e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_attention_scores_head = direct_attention_scores[0, head]  # First batch, head\n",
    "\n",
    "print(torch.allclose(attention_probs_head, direct_attention_scores_head, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17258489-740b-472c-82ff-f628a1222a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fe385-f82f-4fd7-8b3a-bec45e94be8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a8fc2-9a00-4ad6-9c5e-c83a86d3ca1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157b0b6-3df1-4e41-bcbf-47707a24f2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee6a32-6355-4135-a272-8e86b3688f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "876bc273-0489-4729-a536-99f379ce9541",
   "metadata": {},
   "source": [
    "## Nice! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7144b40f-f734-4fe8-8214-1dea2e04b50c",
   "metadata": {},
   "source": [
    "### Now, let's compute the full output after the multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdff66-05ce-44a5-ac92-92585afba5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = torch.matmul(embeddings, v_weight.T) + v_bias\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8abd34-36a3-4ea6-9df3-cb285b0abe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_in_heads = values.view(values.shape[0], values.shape[1], num_heads, head_size).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c48b82-f562-4ec4-a5f7-c36e920628a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values_in_heads.shape)\n",
    "print(direct_attention_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c043f7-3256-4b82-948b-717de8c8213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matmul should handle the first two dimensions nicely\n",
    "\n",
    "weighted_values_per_head = torch.matmul(direct_attention_scores, values_in_heads)\n",
    "weighted_values_per_head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c55d6-b25e-4a69-bac0-509eba71b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(weighted_values_per_head[0][0], torch.matmul(direct_attention_scores_head, values_head[0]), atol=1e-6)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685e443-8c02-476b-8f76-974d122f2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_attention = weighted_values_per_head.permute(0, 2, 1, 3).reshape(1, 6, -1)\n",
    "result = torch.allclose(post_attention[0, 0, 0:64], weighted_values_per_head[0, 0, 0], atol=1e-6)\n",
    "\n",
    "result, post_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39404a08-a535-4a41-949f-a87efed95579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16f076-6dc6-4cb6-b5ed-b08b3d7e8344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030bc48-15eb-4a21-a401-3981c50c30ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3dce6-2b48-4857-b094-4a3d36707b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78080da3-8fb4-4bc6-a025-fc1162904854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7418e94c-8597-4cb2-a631-541e8b2a9515",
   "metadata": {},
   "source": [
    "### Let's find the embeddings at layer 1 now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b996e-450d-43d4-9696-a1cbf642dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb6388-a133-434f-9a79-5b31b5de74a2",
   "metadata": {},
   "source": [
    "## We need to apply a fully connected and another layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13e960-bd1f-4c8a-906a-d3fe3fe19411",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected = model.encoder.layer[0].attention.output.dense\n",
    "layer_norm = model.encoder.layer[0].attention.output.LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979797c-f8ff-47b6-a71b-486795636aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = fully_connected(post_attention)\n",
    "fc2 = fc1 + embeddings\n",
    "fc3 = layer_norm(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e217092-1a60-485c-9deb-f03d7b858123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4eed10-e816-4fea-b5f5-b868b007948d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1d956-882b-4501-a19e-df6e0f56c7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654468b-694a-4cbb-9367-217bc4ea9272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c5e8-14a1-44ce-a20f-967a059b3f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fff0f5-561a-4c53-aa65-c67eade22a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f41889-1274-4163-b941-79df1fca52d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d21fb-e431-489e-b167-71a959d2d9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b24975-bc3d-495d-9912-91dbf97c1bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ffc64-cf65-4a71-9f23-a1073ef8ec8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f10f-f911-4f0b-8685-81c5b4624377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6faff883-0322-4d43-b24b-649440c222c3",
   "metadata": {},
   "source": [
    "## Something Bert has..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a6174-98b8-4d0b-ad03-27ab52d015e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_intermediate = model.encoder.layer[0].intermediate.dense\n",
    "activation = model.encoder.layer[0].intermediate.intermediate_act_fn\n",
    "\n",
    "intermediate1 = fully_connected_intermediate(fc3)\n",
    "intermediate2 = activation(intermediate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a8a1d-03a1-402d-8a34-bafbedefe127",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_output = model.encoder.layer[0].output.dense\n",
    "layer_norm_output = model.encoder.layer[0].output.LayerNorm\n",
    "\n",
    "output1 = fully_connected_output(intermediate2)\n",
    "output2 = output1 + fc3\n",
    "output3 = layer_norm_output(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ddf24-99d6-443e-91d8-ae5049845a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "output3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cb2f1-e12f-471b-b134-426df38997a7",
   "metadata": {},
   "source": [
    "### Remember that we had the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5cbc36-8eb4-4610-a41b-e8d772020e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = model.embeddings(input_ids=input_ids)\n",
    "    assert (embeddings == outputs[2][0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aae427-c18b-4a05-b096-0e1b4ea8813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450b026-2f12-4019-8c61-2a0076e34885",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_layer1 = outputs[2][1]\n",
    "embeddings_layer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22005e8-4251-45ba-9e32-38e90ba90ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce842092-9860-49e7-aa50-8f4d54b68d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef92e4-b709-4a5e-88a7-f6fbc016e85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2f31d-80ce-4344-be3a-98a04ce95dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_we_make_it = torch.allclose(output3, embeddings_layer1, atol=1e-5)\n",
    "did_we_make_it ## ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dab737-e0f0-4801-ae65-cf5af2ed5d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
